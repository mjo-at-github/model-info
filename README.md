# Model info

Simple command line tool written in Go that can be used to obtain info about Triton hosted models (Nvidia's inference server).

### Usage

`go run main.go inception_onnx`

Replace inception_onnx with the name of the model you are interested in querying